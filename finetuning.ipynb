{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "1. Preparation of the training & validation dataset to fine-tune the model\n",
    "2. Using the fine tuned model with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mariajahnke/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json #for the format\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import PyPDF2\n",
    "import nltk\n",
    "import pdfplumber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and tokenising ESG reports\n",
    "\n",
    "The following code block converts pdf files to text. For each individual PDF file `pdf_path` (input) and `text_file_path` (output) must be manually set.\n",
    "\n",
    "Converting process:\n",
    "- loading each ESG pdf individually from pdf_path \n",
    "- extracting text using the PyPDF2.PdfReader in binary read mode ('rb')\n",
    "- output one txt file per ESG report to text_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform pdf to txt\n",
    "def extract_text(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        total_tokens = []\n",
    "        \n",
    "        # go over each page in the PDF\n",
    "        for page in reader.pages:\n",
    "            # Extract text from the page\n",
    "            page_text = page.extract_text() if page.extract_text() else ''\n",
    "            # Tokenize the text\n",
    "            tokens = nltk.word_tokenize(page_text)\n",
    "            total_tokens.extend(tokens)\n",
    "\n",
    "        # Return the text accumulated up to the token limit\n",
    "        final_text = ' '.join(total_tokens)\n",
    "        return final_text\n",
    "\n",
    "# Path to your PDF file, needs to be changed for each pdf file manually\n",
    "pdf_path = 'esg_reportings/Adidas.pdf'\n",
    "\n",
    "# Extracted text from the PDF\n",
    "extracted_text = extract_text(pdf_path)\n",
    "\n",
    "# Path for the output text file\n",
    "text_file_path = 'finetuning-input/adidas.txt'\n",
    "\n",
    "# Write the extracted text to a new text file\n",
    "with open(text_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(extracted_text)\n",
    "\n",
    "#answer if completed\n",
    "print(f\"Text has been extracted and saved to {text_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating text length\n",
    "\n",
    "Validating the token length of the ESG txt files:\n",
    "- setting max tokens for ESG report to 15.000\n",
    "- counting tokens with tokenizer for GPT-3.5 using `tiktoken.get_encoding(\"cl100k_base\")`\n",
    "- iterating over each txt file in the directory using `os.listdir(directory)`\n",
    "- if the file is too long, the file name will be printed to the console and can then be shortened manually\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which reports needs to be manually shortend\n",
    "\n",
    "\n",
    "def verify_text_file_length(input_file_path, max_tokens=15000):\n",
    "    # Initialize the GPT-3.5 tokenizer\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")  # Adjust this if a different encoding is needed for GPT-3.5\n",
    "\n",
    "    # Function to read the content of the file with different encodings\n",
    "    def read_file_with_fallback(path):\n",
    "        encodings = ['utf-8', 'latin1', 'utf-16', 'cp1252']\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                with open(path, 'r', encoding=encoding) as file:\n",
    "                    return file.read()\n",
    "            except (UnicodeDecodeError, FileNotFoundError):\n",
    "                continue\n",
    "        raise UnicodeDecodeError(\"Unable to decode the file with provided encodings\")\n",
    "\n",
    "    # Read the content of the input file\n",
    "    text = read_file_with_fallback(input_file_path)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = enc.encode(text)\n",
    "    \n",
    "    # Check if the token count exceeds the max_tokens limit\n",
    "    if len(tokens) > max_tokens:\n",
    "        print(f\"The file {input_file_path} exceeded {max_tokens} tokens and needs to be shortened.\")\n",
    "\n",
    "\n",
    "directory = './finetuning-input'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        verify_text_file_length(input_file_path=file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of training & validation dataset \n",
    "Constructing the training and validation JSONL using the inputs:\n",
    "- shortened company txt file embedded into OpenAI instructions\n",
    "- G1-3 regulation txt file embedded into OpenAI instructions\n",
    "- `user_prompt` and expected `assistant_answer` from [finetuning_training.csv](finetuning/finetuning_training.csv) and [finetuning_validation.csv](finetuning/finetuning_validation.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def generate_jsonl(input_csv_file_path, output_json_file_path):\n",
    "    # Open the CSV\n",
    "    with open(input_csv_file_path, 'r') as csv_file:\n",
    "        # Create a CSV reader\n",
    "        csv_reader = csv.DictReader(csv_file, delimiter=\";\")\n",
    "        \n",
    "        # Convert each row into a dictionary and add it to a list\n",
    "        data = [row for row in csv_reader]\n",
    "\n",
    "\n",
    "    with open(\"./finetuning-input/G1-3.txt\", 'r') as regulations_file:\n",
    "        regulations_text = regulations_file.read()\n",
    "\n",
    "        with open(output_json_file_path, 'w') as file:\n",
    "            # Write each line to the file\n",
    "            for line in data:\n",
    "                \n",
    "                report_file_path = line['report_txt_path']\n",
    "                with open(report_file_path, 'r') as report_file:\n",
    "                    report_text = report_file.read()\n",
    "\n",
    "                    prompt_instruction = \"You are an ESG analyst answering questions about the provided ESG report in regards to compliance with regulations.\\n\\n # REGULATIONS:\\n \" + regulations_text + \" \\n\\n-----------------\\n\\n # ESG-REPORTING:\\n\" + report_text\n",
    "                    #structure of the json file       \n",
    "                    row = {\n",
    "                        \"messages\": [\n",
    "                            {\"role\": \"system\", \"content\": prompt_instruction},\n",
    "                            {\"role\": \"user\", \"content\": line['user_prompt']},\n",
    "                            {\"role\": \"assistant\", \"content\": line['assistant_answer']}\n",
    "                        ]\n",
    "                    }\n",
    "                    #adding line break to match jsonl format\n",
    "                    file.write(json.dumps(row) + '\\n')\n",
    "\n",
    "\n",
    "# Input csv manually created training dataset & output newly created json file\n",
    "generate_jsonl(\n",
    "    input_csv_file_path=\"finetuning/finetuning_training.csv\", \n",
    "    output_json_file_path=\"finetuning/training.jsonl\"\n",
    ")\n",
    "generate_jsonl(\n",
    "    input_csv_file_path=\"finetuning/finetuning_validation.csv\", \n",
    "    output_json_file_path=\"finetuning/validation.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting\n",
    "\n",
    "- creating one single thread per company -> reusing the same thread for prompt_2 and prompt_3 (chain of thoughts prompting technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as few_shot with using the excel file to upload it in OpenAI\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"personal_API_key\"\n",
    ")\n",
    "\n",
    "def runThread(assistant_id, thread_id, prompt, prompt_instructions):\n",
    "  assistant = client.beta.assistants.retrieve(\n",
    "    assistant_id=assistant_id\n",
    "  )\n",
    "\n",
    "  client.beta.assistants.update(\n",
    "    assistant_id= assistant_id,\n",
    "    instructions=prompt_instructions\n",
    "  )\n",
    "\n",
    "  thread = client.beta.threads.retrieve(\n",
    "    thread_id=thread_id\n",
    "  )\n",
    "\n",
    "  # add message to thread\n",
    "  client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=prompt\n",
    "  )\n",
    "\n",
    "  run = client.beta.threads.runs.create_and_poll(\n",
    "      thread_id=thread.id,\n",
    "      assistant_id=assistant.id,\n",
    "      additional_instructions=prompt_instructions\n",
    "  )\n",
    "\n",
    "  threadMessages = client.beta.threads.messages.list(thread.id)\n",
    "\n",
    "  assistantMessage = next((i for i in threadMessages if i.role == \"assistant\" and i.run_id == run.id), None)\n",
    "  return assistantMessage.content[0].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instructions</th>\n",
       "      <th>assistant_id</th>\n",
       "      <th>prompt_1</th>\n",
       "      <th>answer_1</th>\n",
       "      <th>prompt_2</th>\n",
       "      <th>answer_2</th>\n",
       "      <th>prompt_3</th>\n",
       "      <th>answer_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finetuning-input/Symrise.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>Symrise: The Code of Conduct, which applies gl...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning-input/Vonovia.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Vonovia SE.\\n-...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finetuning-input/VW.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about the ESG report...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finetuning-input/Zalando.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Zalando:\\n- Za...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finetuning-input/DeutscheTelekom.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Deutsche Telek...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>finetuning-input/Symrise.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Symrise and it...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Symrise and it...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Symrise and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>finetuning-input/Vonovia.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following is a compliance check for Vonovi...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following is a compliance check for Vonovi...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following is an analysis of Vonovia SE's E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>finetuning-input/VW.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about the Volkswagen...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about the Volkswagen...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about the Volkswagen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>finetuning-input/Zalando.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Zalando. The E...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Zalando. The E...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Zalando. The E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>finetuning-input/DeutscheTelekom.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following analysis is about Deutsche Telek...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following part is about the independence o...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The following part is about the training progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>finetuning-input/DeutscheTelekom.txt</td>\n",
       "      <td>asst_VyMI4bAcjEea5eQ20D9QGubl</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>Deutsche Telekom:\\n- Deutsche Telekom has a co...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>The investigation committee is not explicitly ...</td>\n",
       "      <td>Provide a short,precise and structured compreh...</td>\n",
       "      <td>Deutsche Telekom:\\n- Deutsche Telekom provides...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            instructions                   assistant_id  \\\n",
       "0           finetuning-input/Symrise.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "1           finetuning-input/Vonovia.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "2                finetuning-input/VW.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "3           finetuning-input/Zalando.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "4   finetuning-input/DeutscheTelekom.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "5           finetuning-input/Symrise.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "6           finetuning-input/Vonovia.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "7                finetuning-input/VW.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "8           finetuning-input/Zalando.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "9   finetuning-input/DeutscheTelekom.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "10  finetuning-input/DeutscheTelekom.txt  asst_VyMI4bAcjEea5eQ20D9QGubl   \n",
       "\n",
       "                                             prompt_1  \\\n",
       "0   Provide a short,precise and structured compreh...   \n",
       "1   Provide a short,precise and structured compreh...   \n",
       "2   Provide a short,precise and structured compreh...   \n",
       "3   Provide a short,precise and structured compreh...   \n",
       "4   Provide a short,precise and structured compreh...   \n",
       "5   Provide a short,precise and structured compreh...   \n",
       "6   Provide a short,precise and structured compreh...   \n",
       "7   Provide a short,precise and structured compreh...   \n",
       "8   Provide a short,precise and structured compreh...   \n",
       "9   Provide a short,precise and structured compreh...   \n",
       "10  Provide a short,precise and structured compreh...   \n",
       "\n",
       "                                             answer_1  \\\n",
       "0   Symrise: The Code of Conduct, which applies gl...   \n",
       "1   The following analysis is about Vonovia SE.\\n-...   \n",
       "2   The following analysis is about the ESG report...   \n",
       "3   The following analysis is about Zalando:\\n- Za...   \n",
       "4   The following analysis is about Deutsche Telek...   \n",
       "5   The following analysis is about Symrise and it...   \n",
       "6   The following is a compliance check for Vonovi...   \n",
       "7   The following analysis is about the Volkswagen...   \n",
       "8   The following analysis is about Zalando. The E...   \n",
       "9   The following analysis is about Deutsche Telek...   \n",
       "10  Deutsche Telekom:\\n- Deutsche Telekom has a co...   \n",
       "\n",
       "                                             prompt_2  \\\n",
       "0                                                   x   \n",
       "1                                                   x   \n",
       "2                                                   x   \n",
       "3                                                   x   \n",
       "4                                                   x   \n",
       "5   Provide a short,precise and structured compreh...   \n",
       "6   Provide a short,precise and structured compreh...   \n",
       "7   Provide a short,precise and structured compreh...   \n",
       "8   Provide a short,precise and structured compreh...   \n",
       "9   Provide a short,precise and structured compreh...   \n",
       "10  Provide a short,precise and structured compreh...   \n",
       "\n",
       "                                             answer_2  \\\n",
       "0                                                   x   \n",
       "1                                                   x   \n",
       "2                                                   x   \n",
       "3                                                   x   \n",
       "4                                                   x   \n",
       "5   The following analysis is about Symrise and it...   \n",
       "6   The following is a compliance check for Vonovi...   \n",
       "7   The following analysis is about the Volkswagen...   \n",
       "8   The following analysis is about Zalando. The E...   \n",
       "9   The following part is about the independence o...   \n",
       "10  The investigation committee is not explicitly ...   \n",
       "\n",
       "                                             prompt_3  \\\n",
       "0                                                   x   \n",
       "1                                                   x   \n",
       "2                                                   x   \n",
       "3                                                   x   \n",
       "4                                                   x   \n",
       "5   Provide a short,precise and structured compreh...   \n",
       "6   Provide a short,precise and structured compreh...   \n",
       "7   Provide a short,precise and structured compreh...   \n",
       "8   Provide a short,precise and structured compreh...   \n",
       "9   Provide a short,precise and structured compreh...   \n",
       "10  Provide a short,precise and structured compreh...   \n",
       "\n",
       "                                             answer_3  \n",
       "0                                                   x  \n",
       "1                                                   x  \n",
       "2                                                   x  \n",
       "3                                                   x  \n",
       "4                                                   x  \n",
       "5   The following analysis is about Symrise and it...  \n",
       "6   The following is an analysis of Vonovia SE's E...  \n",
       "7   The following analysis is about the Volkswagen...  \n",
       "8   The following analysis is about Zalando. The E...  \n",
       "9   The following part is about the training progr...  \n",
       "10  Deutsche Telekom:\\n- Deutsche Telekom provides...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_file_as_text(path):\n",
    "    with open(path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "excel_file_path = \"analysis/finetuning.xlsx\"\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(excel_file_path, sheet_name='Sheet1', keep_default_na=False)\n",
    "\n",
    "regulations_text = read_file_as_text(\"./finetuning-input/G1-3.txt\")\n",
    "\n",
    "# Iterate over DataFrame rows\n",
    "for i in df.index:\n",
    "\n",
    "    report_text = read_file_as_text(df.loc[i, 'instructions'])\n",
    "\n",
    "    prompt_instructions = \"You are an ESG analyst answering questions about the provided ESG report in regards to compliance with regulations.\\n\\n # REGULATIONS:\\n \" + regulations_text + \" \\n\\n-----------------\\n\\n # ESG-REPORTING:\\n\" + report_text\n",
    "\n",
    "    if df.loc[i, 'answer_1'] == '':\n",
    "        thread = client.beta.threads.create()\n",
    "\n",
    "        answer1 = runThread(\n",
    "            assistant_id=df.loc[i, 'assistant_id'],\n",
    "            thread_id=thread.id,\n",
    "            prompt=df.loc[i, 'prompt_1'],\n",
    "            prompt_instructions=prompt_instructions\n",
    "        )\n",
    "        df.loc[i, 'answer_1'] = answer1\n",
    "\n",
    "        if df.loc[i, 'answer_2'] == '':\n",
    "            answer2 = runThread(\n",
    "                assistant_id=df.loc[i, 'assistant_id'],\n",
    "                thread_id=thread.id,\n",
    "                prompt=df.loc[i, 'prompt_2'],\n",
    "                prompt_instructions= prompt_instructions\n",
    "            )\n",
    "            df.loc[i, 'answer_2'] = answer2\n",
    "\n",
    "            if df.loc[i, 'answer_3'] == '':\n",
    "                answer3 = runThread(\n",
    "                    assistant_id=df.loc[i, 'assistant_id'],\n",
    "                    thread_id=thread.id,\n",
    "                    prompt=df.loc[i, 'prompt_3'],\n",
    "                    prompt_instructions= prompt_instructions\n",
    "                )\n",
    "                df.loc[i, 'answer_3'] = answer3  \n",
    "\n",
    "        # Save the DataFrame back to the Excel file\n",
    "        df.to_excel(excel_file_path, index=False, sheet_name='Sheet1')\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-Qupte5kC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
